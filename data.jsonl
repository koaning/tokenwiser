{"text":"LANe: Lighting-Aware Neural Fields for Compositional Scene Synthesis","new-dataset":0}
{"text":"Neural fields have recently enjoyed great success in representing and rendering 3D scenes.","new-dataset":0}
{"text":"However, most state-of-the-art implicit representations model static or dynamic scenes as a whole, with minor variations.","new-dataset":0}
{"text":"Existing work on learning disentangled world and object neural fields do not consider the problem of composing objects into different world neural fields in a lighting-aware manner.","new-dataset":0}
{"text":"We present Lighting-Aware Neural Field (LANe) for the compositional synthesis of driving scenes in a physically consistent manner.","new-dataset":0}
{"text":"Specifically, we learn a scene representation that disentangles the static background and transient elements into a world-NeRF and class-specific object-NeRFs to allow compositional synthesis of multiple objects in the scene.","new-dataset":0}
{"text":"Furthermore, we explicitly designed both the world and object models to handle lighting variation, which allows us to compose objects into scenes with spatially varying lighting.","new-dataset":0}
{"text":"This is achieved by constructing a light field of the scene and using it in conjunction with a learned shader to modulate the appearance of the object NeRFs.","new-dataset":0}
{"text":"We demonstrate the performance of our model on a synthetic dataset of diverse lighting conditions rendered with the CARLA simulator, as well as a novel real-world dataset of cars collected at different times of the day.","new-dataset":0}
{"text":"Our approach shows that it outperforms state-of-the-art compositional scene synthesis on the challenging dataset setup, via composing object-NeRFs learned from one scene into an entirely different scene whilst still respecting the lighting variations in the novel scene.","new-dataset":0}
{"text":"For more results, please visit our project website https://lane-composition.github.io/.","new-dataset":0}
{"text":"Neural Fields meet Explicit Geometric Representation for Inverse Rendering of Urban Scenes","new-dataset":0}
{"text":"Reconstruction and intrinsic decomposition of scenes from captured imagery would enable many applications such as relighting and virtual object insertion.","new-dataset":0}
{"text":"Recent NeRF based methods achieve impressive fidelity of 3D reconstruction, but bake the lighting and shadows into the radiance field, while mesh-based methods that facilitate intrinsic decomposition through differentiable rendering have not yet scaled to the complexity and scale of outdoor scenes.","new-dataset":0}
{"text":"We present a novel inverse rendering framework for large urban scenes capable of jointly reconstructing the scene geometry, spatially-varying materials, and HDR lighting from a set of posed RGB images with optional depth.","new-dataset":0}
{"text":"Specifically, we use a neural field to account for the primary rays, and use an explicit mesh (reconstructed from the underlying neural field) for modeling secondary rays that produce higher-order lighting effects such as cast shadows.","new-dataset":0}
{"text":"By faithfully disentangling complex geometry and materials from lighting effects, our method enables photorealistic relighting with specular and shadow effects on several outdoor datasets.","new-dataset":0}
{"text":"Moreover, it supports physics-based scene manipulations such as virtual object insertion with ray-traced shadow casting.","new-dataset":0}
{"text":"On the Pareto Front of Multilingual Neural Machine Translation","new-dataset":0}
{"text":"In this work, we study how the generalization performance of a given direction changes with its sampling ratio in Multilingual Neural Machine Translation (MNMT).","new-dataset":0}
{"text":"By training over 200 multilingual models with various model sizes, directions, and total numbers of tasks, we find that scalarization leads to a multitask trade-off front that deviates from the traditional Pareto front when there exists data imbalance in the training corpus.","new-dataset":0}
{"text":"That is, the performance of certain translation directions does not improve with the increase of its weight in the multi-task optimization objective, which poses greater challenge to improve the overall performance of all directions.","new-dataset":0}
{"text":"Our dataset is available online.","new-dataset":1}
{"text":"We will release the dataset and code to facilitate future endeavors.","new-dataset":1}
{"text":"We extensively evaluate the method on various target datasets including fresh-produce dataset, HRSC2016 and SSDD.","new-dataset":0}
{"text":"Our methods are complementary to the existing pre-training or data mining approaches and can be used in a variety of settings.","new-dataset":0}
{"text":"This paper aims to explore different methodologies with an intention to achieve a cost-effective model with a higher accuracy with different types of the datasets, which is to address the generalizability of the dataset.","new-dataset":0}
{"text":"Experimental evaluations both on our assembled dataset and public benchmark datasets demonstrate the effectiveness of our proposed network.","new-dataset":0}
{"text":"We validate our scheme with some of the most popular benchmarking datasets.","new-dataset":0}
{"text":"Code and dataset are available at https://github.com/zhangzilongc/MMR.","new-dataset":1}
{"text":"These metrics have been successful on datasets that leverage the average human perception in limited settings.","new-dataset":0}
{"text":"To evaluate our approach, we construct a large-scale object-centric dataset containing over 520K images of vehicles and pedestrians from the Waymo Open Dataset, and a new set of 80K images of long-tail instances such as construction equipment, garbage trucks, and cable cars.","new-dataset":1}
{"text":"The CrowdAI Mapping Challenge Dataset is one of these datasets that has been used extensively in recent years to train deep neural networks.","new-dataset":0}
{"text":"Experimental results demonstrate the performance and limitations of existing algorithms, and the dataset benchmark has good versatility and effectiveness.","new-dataset":0}
{"text":"To this end, we generate two synthetic datasets and then develop an end-to-end pipeline and model that is tested on both benchmarks.","new-dataset":1}
{"text":"Our framework combines task knowledge of an out-of-domain source dataset with stronger annotation and domain knowledge of the target dataset with weaker annotation.","new-dataset":0}
{"text":"Existing IAD datasets focus on the diversity of data categories, overlooking the diversity of domains within the same data category.","new-dataset":0}
{"text":"The dataset is available for download at: https://ustc-flicar.github.io.","new-dataset":1}
{"text":"To support a large-scale investigation, we construct the first DGM^4 dataset, where image-text pairs are manipulated by various approaches, with rich annotation of diverse manipulations.","new-dataset":1}
{"text":"However, existing large-scale video-text datasets and mining techniques suffer from several limitations, such as the scarcity of aligned data, the lack of diversity in the data, and the difficulty of collecting aligned data.","new-dataset":0}
{"text":"We conducted extensive experiments and evaluations on several benchmark datasets, including image classification, object detection, natural language processing, and graph-based learning tasks.","new-dataset":0}
{"text":"Using the newly-curated dataset, we evaluate a set of the most recent in-context learners and compare their results to the supervised baselines.","new-dataset":1}
{"text":"Our approach is validated on two existing datasets and our newly introduced dataset, showing better clothing deformation results in unseen poses.","new-dataset":1}
{"text":"The system follows a high-level recipe that leverages various generative methods to produce new visualizations that retain the properties of the original dataset.","new-dataset":0}
{"text":"By learning the rules of charts automatically from annotated datasets, our approach eliminates the need for manual rule-making, reducing effort and enhancing accuracy.~We also introduce a data variable replacement technique and extend the input and position embeddings of the pre-trained model for cross-task training.","new-dataset":0}
{"text":"Finally, we demonstrate the scalability of $\\texttt{torch-choice}$ on large-scale datasets.","new-dataset":0}
{"text":"In this paper, we follow a data-centric philosophy and propose a novel motion annotation method based on the inherent representativeness of motion data in a given dataset.","new-dataset":0}
{"text":"In recent years, numerous public datasets have played significant roles in the advancement of autonomous cars and unmanned aerial vehicles (UAVs).","new-dataset":0}
{"text":"Given the lack of existing datasets suitable for the task, we also extend two existing fashion datasets, namely Dress Code and VITON-HD, with multimodal annotations collected in a semi-automatic manner.","new-dataset":1}
{"text":"Experiment results on real-world datasets MLQA demonstrate that the proposed method can improve the performance by a large margin, outperforming the baseline method by 13.18%/12.00% F1/EM on average.","new-dataset":0}
{"text":"We fine-tune these networks on several video captioning datasets.","new-dataset":0}
{"text":"This dataset consists of $ \\sim\\ $280k training images and $ \\sim\\ $60k testing images, with polygonal building annotations for all images.","new-dataset":1}
{"text":"The project page with code and dataset can be found at https://www.liuyebin.com/closet.","new-dataset":1}
{"text":"We provide extensive evaluation on four challenging underwater datasets.","new-dataset":0}
{"text":"Our codes and dataset could be found at https://github.com/Paul-LiPu/DeepVideoHomography","new-dataset":1}
{"text":"The proposed dataset extends the typical autonomous driving sensing suite to aerial scenes.","new-dataset":1}
{"text":"We link a diverse set of datasets and cast these into a unified instructional format through a set of transformations and newly-crafted templates written purely in target languages.","new-dataset":0}
{"text":"Experimental results on these new datasets demonstrate the effectiveness of our proposal, both in terms of realism and coherence with the given multimodal inputs.","new-dataset":0}
{"text":"Finally, the dataset provides the basis for a dedicated track at the 2023 Text Retrieval Conference (TREC), and is publicly available at https://github.com/TREC-AToMiC/AToMiC.","new-dataset":1}
{"text":"To enable this, we introduce a large crowd-sourced dataset of images captured across 12 cities from the diverse viewpoints of cars, bikes, and pedestrians.","new-dataset":1}
{"text":"However, issues such as low-quality and incorrect annotations, extensive duplication of image samples, and data leakage significantly reduce the utility of deep neural networks trained on the dataset.","new-dataset":0}
{"text":"OrienterNet generalizes to new datasets and pushes the state of the art in both robotics and AR scenarios.","new-dataset":0}
{"text":"The source code and dataset are available at project page.","new-dataset":1}
{"text":"The first challenge is how to distribute the data.","new-dataset":0}
{"text":"Experimental results on the HDM05 dataset against state-of-the-art methods demonstrate the superiority of our method.","new-dataset":0}
{"text":"We believe this dataset can also represent the flying car scenarios, specifically the takeoff and landing of VTOL (Vertical Takeoff and Landing) flying cars.","new-dataset":1}
{"text":"This work promotes the communication of research protocols when publishing datasets, benefiting researchers when designing experiments.","new-dataset":0}
{"text":"In this paper, to bridge this gap, we propose the Aero-engine Blade Anomaly Detection (AeBAD) dataset, consisting of two sub-datasets: the single-blade dataset and the video anomaly detection dataset of blades.","new-dataset":1}
{"text":"We use it to train a simple convolutional neural network (ConvNet) with a fully supervised objective.","new-dataset":0}
{"text":"Extensive experimental results on three public real-world datasets demonstrate that QKT achieves state-of-the-art performance compared to existing methods.","new-dataset":0}
{"text":"The diversity of the datasets is the foundation for developing comprehensive IAD algorithms.","new-dataset":0}
{"text":"Datasets, source code and pre-trained models are available at \\url{https://github.com/chdwyb/RSFormer}.","new-dataset":1}
{"text":"The source code used for the analysis and de-duplication of the CrowdAI Mapping Challenge dataset is publicly available at https://github.com/yeshwanth95/CrowdAI_Hash_and_search .","new-dataset":0}
{"text":"To our knowledge, this is the first publicly available instance-level logo sketch dataset.","new-dataset":1}
{"text":"To begin with, we construct an instance-level logo sketch dataset containing 2k logo instances and exceeding 9k sketches.","new-dataset":1}
{"text":"Extensive experiments demonstrate that MCL consistently outperforms the recent state-of-the-art methods on various datasets with significant margins.","new-dataset":0}
{"text":"To facilitate the research in this field, we also introduce a high-quality scan dataset of humans in real-world clothing.","new-dataset":1}
{"text":"Extensive experiments on the large-scale Waymo Open Dataset and nuScenes Dataset demonstrate that VPFusion surpasses the single-stream baselines by a large margin and achieves state-of-the-art performance with real-time inference speed.","new-dataset":0}
{"text":"Large-scale rare events data are commonly encountered in practice.","new-dataset":0}
{"text":"We introduce a new learner, SP-GIES, that jointly learns from interventional and observational datasets and achieves almost 4x speedup against an existing learner for 1,000 node networks.","new-dataset":0}
{"text":"Moreover, our results render contrastive training a viable alternative to point-wise classification objectives.","new-dataset":0}
{"text":"The package incorporates the option to take advantage of GPUs for estimation, allowing it to scale to massive datasets while being computationally efficient.","new-dataset":0}
{"text":"Scaling up weakly-supervised datasets has shown to be highly effective in the image-text domain and has contributed to most of the recent state-of-the-art computer vision and multimodal neural networks.","new-dataset":0}
{"text":"Efficient Deduplication and Leakage Detection in Large Scale Image Datasets with a focus on the CrowdAI Mapping Challenge Dataset","new-dataset":0}
{"text":"Compared to existing datasets, AeBAD has the following two characteristics: 1.)","new-dataset":1}
{"text":"To this end, we propose a drop-in pipeline that employs perceptual hashing techniques for efficient de-duplication of the dataset and identification of instances of data leakage between training and testing splits.","new-dataset":0}
{"text":"We identify the challenges involved in modeling scenes for these tasks and the kind of machinery that needs to be developed to adapt to the data representation, and the task setting in general.","new-dataset":0}
{"text":"Despite its simplicity, our approach can even surpass soft-prompt learning methods as shown by extensive experiments on 11 image and 2 video datasets.","new-dataset":0}
{"text":"In the absence of such assumptions, existing work requires multiple observations of datasets that contain the same treatment and outcome variables, in order to establish bounds on these probabilities.","new-dataset":0}
{"text":"Replicability and Transparency for the Creation of Public Human User Video Game Datasets","new-dataset":0}
{"text":"We extend our pretext task to supervised pre-training, which achieves a similar performance to self-supervised learning.","new-dataset":0}
{"text":"Finally, the trained metrics are evaluated on a perceptual similarity dataset to evaluate if adapting to an ordering affects their performance on established scenarios.","new-dataset":0}
{"text":"In particular, we make in-depth analyses on how to represent a data point in the feature space, how to calculate a fair distance using selected samples, and how many instances to use from each set.","new-dataset":0}
{"text":"Finally, we train, evaluate and publish a set of in-context learning models that we train on the collected resources and compare their performance to previous work.   ","new-dataset":0}
{"text":"This paper presents the AToMiC (Authoring Tools for Multimedia Content) dataset, designed to advance research in image/text cross-modal retrieval.","new-dataset":1}
{"text":"The prediction network is trained from a dataset of unlabelled images depicting people in typical poses and a set of unpaired 2D poses.","new-dataset":0}
{"text":"While vision-language pretrained transformers have led to significant improvements in retrieval effectiveness, existing research has relied on image-caption datasets that feature only simplistic image-text relationships and underspecified user models of retrieval tasks.","new-dataset":0}
{"text":"For each of these tasks, we provide a comprehensive summary of the state-of-the-art works across different axes such as the choice of data representation, backbone, evaluation metric, input, output, etc., providing an organized review of the literature.","new-dataset":0}
{"text":"This study develops a high-quality human motor element dataset based on the Laban Movement Analysis movement coding system and utilizes that to jointly learn about motor elements and emotions.","new-dataset":0}
{"text":"Experiments on synthetic, semi-synthetic, and real-world datasets demonstrate that our proposed method outperforms state-of-the-art methods by a large margin in terms of both objective PSNR and SSIM measurements and subjective evaluations.","new-dataset":0}
{"text":"Recently these systems have proved to perform better than humans on held-out test sets of datasets e.g. SQuAD, but their robustness is not guaranteed.","new-dataset":0}
{"text":"To promote research in 3D volumetric image analysis beyond medical data, we have created the BugNIST dataset and made it freely available.","new-dataset":1}
{"text":"Therefore, the dataset is named FLICAR to denote flying cars.","new-dataset":1}
{"text":"This is the case of robotic applications where no datasets of the objects exist or application that includes thousands of objects (E.g., in logistics) where it is impossible to train a single model to learn all of the objects.","new-dataset":0}
{"text":"This paper is divided into four sections: dataset, model architecture, training and analysis.","new-dataset":1}
{"text":"We also present EduceLab-Scrolls, a comprehensive open dataset representing two decades of research effort on this problem.","new-dataset":1}
{"text":"Our dataset is available online.","new-dataset":1}
{"text":"Experiments on real-world datasets demonstrate the effectiveness of our approach.","new-dataset":1}
{"text":"To demonstrate the generalizability of our proposed features and model we test the model on BHBID dataset and an internal dataset where we attain accuracy of 98% and 91%, respectively.","new-dataset":0}
{"text":"We will release the dataset and code to facilitate future endeavors.","new-dataset":1}
{"text":"To our knowledge, this is the first aligned dataset of its kind and is the largest dataset ever released in the heritage domain.","new-dataset":1}
{"text":"In order to implement deep learning models, a suitable dataset is required.","new-dataset":0}
{"text":"The results show a noticeable improvement in generalization on the 3RL dataset.","new-dataset":0}
{"text":"Experimental results demonstrate the performance and limitations of existing algorithms, and the dataset benchmark has good versatility and effectiveness.","new-dataset":0}
{"text":"These datasets included the latest second and third generation deepfake datasets.","new-dataset":0}
{"text":"Furthermore, we propose an approximation that allows our method to scale to datasets consisting of millions of data points.","new-dataset":0}
{"text":"This paper aims to explore different methodologies with an intention to achieve a cost-effective model with a higher accuracy with different types of the datasets, which is to address the generalizability of the dataset.","new-dataset":0}
{"text":"It has the potential to serve as a cornerstone dataset for developing more general visual perception systems.","new-dataset":1}
{"text":"Here we step in with a novel method that identifies the features that allow to discriminate data subsets of different sizes.","new-dataset":0}
{"text":"The dataset with accompanying code can be downloaded from our website.","new-dataset":1}
{"text":"Extensive experiments have proved the effectiveness of our method with improved results on the VQA-CP dataset.","new-dataset":0}
{"text":"For this purpose, we built synthetic datasets with nonlinearly separable classes and increasing number of decoy (random) features, illustrating the challenge of FS in high-dimensional settings.","new-dataset":0}
{"text":"We improve the selection process for the evaluation dataset, and we reduce the numbers of identities contained in the dataset while ensuring that these identities remain easily distinguishable from one another.","new-dataset":0}
{"text":"Our results show that our simple synthetic datasets are sufficient to challenge most of the benchmarked methods.","new-dataset":0}
{"text":"In this paper, we proposed a new task setting to improve the classification performance of the target dataset without increasing annotation costs.","new-dataset":0}
{"text":"What we possess are numerous isolated filed-specific datasets, thus, it is appealing to jointly pretrain models across aggregation of datasets to enhance data volume and diversity.","new-dataset":0}
{"text":"These metrics have been successful on datasets that leverage the average human perception in limited settings.","new-dataset":0}
{"text":"Experimental evaluations both on our assembled dataset and public benchmark datasets demonstrate the effectiveness of our proposed network.","new-dataset":1}
{"text":"We further demonstrate that it can boost performance with small amounts of supervised data.","new-dataset":0}
{"text":"The 3RL dataset was created, which contains approximately 24K images and will be publicly available, to overcome previously available dataset problems.","new-dataset":1}
{"text":"The composed dataset is more comprehensive than using any public dataset alone.","new-dataset":1}
{"text":"Extensive experiments conducted on two benchmark datasets show that our approach achieves excellent performance compared to its competitors.","new-dataset":0}
{"text":"We validate our scheme with some of the most popular benchmarking datasets.","new-dataset":0}
{"text":"We test our method on two public datasets, our method achieves the best performances on these two datasets.","new-dataset":0}
{"text":"We describe the process of creating this dataset and report performance of multiple models trained using BenCoref.","new-dataset":1}
{"text":"The PIKS technique is scalable and can readily ingest new datasets.","new-dataset":0}
{"text":"We additionally create MultiON 2.0, a new large-scale dataset as a test-bed for our approach.","new-dataset":1}
{"text":"The models are pretrained on the ImageNet dataset, and fine-tuned using a new real-world binary crack dataset consisting of 14000 samples.","new-dataset":1}
{"text":"Empirically, our method achieves better performance than all baselines on multiple datasets.","new-dataset":0}
{"text":"We extensively evaluate the method on various target datasets including fresh-produce dataset, HRSC2016 and SSDD.","new-dataset":0}
{"text":"Real-world datasets are often of high dimension and effected by the curse of dimensionality.","new-dataset":0}
{"text":"Extensive evaluations on the MSTAR dataset and six DNN models prove the effectiveness of our proposal.","new-dataset":0}
{"text":"We evaluated the dataset using the YOLOv7 algorithm, achieving a mean average precision (map) of up to 85.3%.","new-dataset":0}
{"text":"Visual question answering (VQA) is a critical multimodal task in which an agent must answer questions according to the visual cue.","new-dataset":0}
{"text":"Owing to the lack of relevant datasets, we collect two large-scale benchmark datasets from Taobao Mall and Live domains with about 474k and 101k image-query pairs for PR, and manually annotate the object bounding boxes in each image for PG.","new-dataset":1}
{"text":"Second, to benchmark Open-Vocabulary VIS, we collect a Large-Vocabulary Video Instance Segmentation dataset(LV-VIS), that contains well-annotated objects from 1,212 diverse categories, significantly surpassing the category size of existing datasets by more than one order of magnitude.","new-dataset":1}
{"text":"To facilitate the development of more general visual object detection, we propose V3Det, a vast vocabulary visual detection dataset with precisely annotated bounding boxes on massive images.","new-dataset":1}
{"text":"The resulting fabricated data guarantees not only differential privacy but also ensures that the KAHM modeling error is not larger than that of the original training data samples.","data-quality":0}
{"text":"We also address the accuracy-loss issue that arises with differentially private classifiers by using fabricated data.","data-quality":0}
{"text":"Checking the reliability of opacity databases","data-quality":1}
{"text":"Benchmarking Robustness to Text-Guided Corruptions","data-quality":1}
{"text":"To ensure privacy-preserving learning, we propose a novel method for generating fabricated data, which involves smoothing differentially private data samples through a transformation process.","data-quality":0}
{"text":"Our algorithms leverage compression for privacy amplification: when each client communicates only partial information about its sample, we show that privacy can be amplified by randomly selecting the part contributed by each client.","data-quality":0}
{"text":"Based on experiments, we find that the Flush+Reload-based inference leakage can achieve an 84.0\\% attacking success rate to identify the labels of the two samples in DTW.","data-quality":1}
{"text":"In spite of the progress in music source separation research, the small amount of publicly-available clean source data remains a constant limiting factor for performance.","data-quality":0}
{"text":"The problem is the sale of user data to third parties.","data-quality":0}
{"text":"A variety of flaws in common evaluation protocols have caused leading approaches to focus on problems that do not exist in real data.","data-quality":0}
{"text":"Our paper asks, how do LLMs trained on open data sets circumvent the copyright interests of the used data?","data-quality":1}
{"text":"Another major progress recently established that the bit error probability vanishes slowly below capacity.","data-quality":0}
{"text":"Conflict-free Replicated Data Types (CRDTs) allow collaborative access to an app's data.","data-quality":0}
{"text":"In one case they reduce data misses on the highest performance L1 cache dramatically by 47 percent.","data-quality":0}
{"text":"In this paper, we propose a data correction pipeline to generate ground-truth data more efficiently in this semi-automated scenario.","data-quality":1}
{"text":"As a building block for the transcoding sampler we develop the i.i.d. transcoding algorithm which, conditional to a posterior partition of the data, can infer back which specific stick in the stick-breaking construction each observation originated from.","data-quality":0}
{"text":"Crucially, this includes conditions in which only a small amount of labeled data is available.","data-quality":0}
{"text":"In real-world scenarios, clients may have Non-IID data (local class imbalance) with poor annotation quality (label noise).","data-quality":1}
{"text":"By separating the generation of different components in the samples, our framework composes visually promising whistle data and labels even when few expert annotated data are available.","data-quality":0}
{"text":"We evaluate the effectiveness of the method by measuring its robustness against label noise in classification.","data-quality":1}
{"text":"However, corresponding class labels are noisy when provided by error-prone annotators, e.g., crowd workers.","data-quality":1}
{"text":"Inferencing unlabeled data from labeled data is an error-prone process.","data-quality":0}
{"text":"In this work, we step further to study the leakage in the scenario of the regression model, where the private labels are continuous numbers (instead of discrete labels in classification).","data-quality":1}
{"text":"This is partially due to the fact that obtaining a balanced, diverse, and perfectly labeled dataset is typically expensive, time-consuming, and error-prone.","data-quality":0}
{"text":"Data leakage is a well-known problem in machine learning.","data-quality":0}
{"text":"Identifying the samples with corrupted labels and preventing the model from learning them is a promising approach to address this challenge.","data-quality":1}
{"text":"However, it usually suffers from a lack of high-quality datasets due to high annotation cost, inter-observer variability, human annotator error, and errors in computer-generated labels.","data-quality":0}
{"text":"Furthermore, we evaluate issues of information leakage, and test the generalizability of our models on the new dataset.","data-quality":0}
{"text":"Inaccurate Label Distribution Learning","data-quality":1}
{"text":"A comprehensive analysis of our approach and of users' historical data reveals a temporal data leakage problem in the dataset.","data-quality":1}
{"text":"In our analysis, we find that SoundDesc contains several duplicates that cause leakage of training data to the evaluation data.","data-quality":1}
{"text":"Nevertheless, few papers have tackled the data shift problem in labeled training sets, which occurs when there is a mismatch between the data distribution in the training set and the testing set.","data-quality":0}
{"text":"The main anomaly was found by the autoencoder and automatically created labels and was also recorded in the log files.","data-quality":0}
{"text":"Making Split Learning Resilient to Label Leakage by Potential Energy Loss","data-quality":1}
{"text":"Experiment results show that our method significantly lowers the attacker's fine-tuning accuracy, making the split model more resilient to label leakage.","data-quality":1}
{"text":"We find that the above issues are caused by the training dataset's pose imbalance.   ","data-quality":1}
{"text":"Identifying Incorrect Annotations in Multi-Label Classification Data","data-quality":1}
{"text":"Understanding the risk of LMs leaking Personally Identifiable Information (PII) has received less attention, which can be attributed to the false assumption that dataset curation techniques such as scrubbing are sufficient to prevent PII leakage.","data-quality":0}
{"text":"A critical challenge pertains to how much information these models retain and leak about the training data.","data-quality":0}
{"text":"We find that fixing data leaks can drastically reduce model performance, in some cases even making the models perform similarly to a random classifier.","data-quality":1}
{"text":"Moreover, our analysis on the validation split demonstrates that roughly 56k of the 60k images also appear in the training split, resulting in a data leakage of 93%.","data-quality":1}
{"text":"However, we find that the most widely-used outlier injection approach has a serious data leakage issue.","data-quality":1}
{"text":"Furthermore, we detect real label errors a) on commonly used test datasets in object detection and b) on a proprietary dataset.","data-quality":1}
{"text":"Extensive experimentation with real world and synthetic datasets demonstrates significant privacy leakage through recourses.","data-quality":0}
{"text":"This data leakage ultimately leads to overly optimistic retrieval performance estimates in previous benchmarks.","data-quality":1}
{"text":"We tested different data labeling methods and learned how they affect model performance, achieving precisions above 90%.","data-quality":1}
{"text":"In this paper, we investigate the third type of exploitation of data poisoning - increasing the risks of privacy leakage of benign training samples.","data-quality":1}
{"text":"By focusing on finding incorrect labels in the original training datasets, we can eliminate erroneous examples in their root.","data-quality":1}
{"text":"However, some recent works have shown that the private labels could be leaked by the gradients.","data-quality":1}
{"text":"Finally, we perform error analysis and show that label noise is still the largest challenge for improving performance.","data-quality":1}
{"text":"Here we consider algorithms for finding mislabeled examples in multi-label classification datasets.","data-quality":1}
{"text":"In this work, we examine the problem for both labeled and unlabeled settings.","data-quality":0}
{"text":"Mislabeled examples are a common issue in real-world data, particularly for tasks like token classification where many labels must be chosen on a fine-grained basis.","data-quality":1}
{"text":"The leakage is caused by the correlation between the intermediate representations and the raw data.","data-quality":1}
{"text":"As a result, we are able to partially attribute the leakage of the training data in a deep network to its architecture.","data-quality":1}
{"text":"Experimental results on two real-world datasets indicate a great danger of user behavior leakage.","data-quality":1}
{"text":"Confound-leakage: Confound Removal in Machine Learning Leads to Leakage","data-quality":1}
{"text":"This challenge becomes even more difficult to overcome when there exists a significant number of annotation errors in the dataset.","data-quality":0}
{"text":"And yet, we demonstrate that this \"perfect\" filter does not prevent the leakage of training data.","data-quality":1}
{"text":"Label Inference Attack against Split Learning under Regression Setting","data-quality":0}
{"text":"PEOPL: Characterizing Privately Encoded Open Datasets with Public Labels","data-quality":0}
{"text":"However, issues such as low-quality and incorrect annotations, extensive duplication of image samples, and data leakage significantly reduce the utility of deep neural networks trained on the dataset.","data-quality":1}
{"text":"With the wide-spread application of machine learning models, it has become critical to study the potential data leakage of models trained on sensitive data.","data-quality":1}
{"text":"Manually labelling data with high-quality labels is generally a time-consuming and challenging task and often this turns out to be the bottleneck in a machine learning project.","data-quality":0}
{"text":"Experiments on publicly available datasets demonstrate that our method achieves superior results to state-of-the-art methods by 20\\%, and to supervised models trained directly on the target data.","data-quality":0}
{"text":"Supervised machine learning methods provide a highly accurate solution, but require manual labels which are often unavailable.","data-quality":0}
{"text":"The field of machine learning has rapidly advanced the state of the art in many fields of science and engineering, including experimental fluid dynamics, which is one of the original big-data disciplines.","data-quality":0}
{"text":"Machine learning (ML) can help fight pandemics like COVID-19 by enabling rapid screening of large volumes of images.","data-quality":0}
{"text":"Recently, many frameworks for machine unlearning have been proposed, and most of them focus on image and text data.","data-quality":0}
{"text":"Our methods are complementary to the existing pre-training or data mining approaches and can be used in a variety of settings.","data-quality":0}
{"text":"With the development of information science and technology, various industries have generated massive amounts of data, and machine learning is widely used in the analysis of big data.","data-quality":0}
{"text":"When trained on real data, our method also achieves state-of-the-art results.","data-quality":0}
{"text":"This approach increases data efficiency, reduce overfitting via shared representations, and ensure fast learning by leveraging auxiliary information.","data-quality":0}
{"text":"However, these annotations are inherently subjective and some of the instances are hard to classify, resulting in noisy annotations due to error or lack of agreement.","data-quality":1}
{"text":"With many possible classes to consider, data annotators are likely to make errors when labeling such data in practice.","data-quality":1}
{"text":"However, corresponding class labels are noisy when provided by error-prone annotators, e.g., crowd workers.","data-quality":1}
{"text":"We also present a simple yet efficient and effective method of enhancing emotion lexicons to take both semantic shift and the domain of the text into account producing real-world congruent results closely matching both contemporary and modern qualitative analyses.","data-quality":1}
{"text":"Scenario labeling is automated with LMs, which are more performant than human annotators.","data-quality":1}
{"text":"However, such annotations may fail in practice because of the change in annotation requirements, application scenarios, and modeling goals, where label validation and relabeling by domain experts are required.","data-quality":1}
{"text":"We tested the quality of automatic sentiment analysis by comparing automatic labeling with three human raters and tested the robustness of topic modelling by comparing the generated models based on automatic and manually transcribed spoken answers.","data-quality":1}
{"text":"A two-step human annotation and inter-annotator agreement study guarantee the high quality of the PcMSP corpus.","data-quality":1}
{"text":"To answer our question, we consider noncomplex Convolutional Neural Networks (CNNs) based classifiers for recognizing Ekman emotions.","data-quality":0}
{"text":"Methodologically we utilize affective word embeddings to look at the affective distribution in different text segments.","data-quality":0}
{"text":"Here we consider the task of finding sentences that contain label errors in token classification datasets.","data-quality":1}
{"text":"Errors can be easily introduced during annotation and overlooked during review, yielding inaccurate benchmarks and performance degradation of deep neural networks trained on noisy labels.","data-quality":1}
{"text":"A significant amount of works exist on crowd counting using perfectly labelled datasets but none of these explore the impact of annotation errors on the model accuracy.","data-quality":1}
{"text":"We experiment with this method using the label hierarchy of iNaturalist 2021, and observe a 8.76% relative improvement of the error rate over the baseline.","data-quality":1}
{"text":"This paper addresses a multi-task joint learning approach which combines external emotional features extracted from another corpora in dealing with the imbalanced and scarcity of labeled datasets.","data-quality":0}
{"text":"In precision-recall evaluations based on real-world label errors in entity recognition data from CoNLL-2003, we identify a simple and effective method that consistently detects those sentences containing label errors when applied with different token classification models.","data-quality":1}
{"text":"We propose two metrics to audit the noise of annotations.","data-quality":1}
{"text":"Our findings indicate MaDL's state-of-the-art performance and robustness against many correlated, spamming annotators.","data-quality":1}
{"text":"Detecting Label Errors in Token Classification Data","data-quality":1}
{"text":"We propose an extension of the Confident Learning framework to this setting, as well as a label quality score that ranks examples with label errors much higher than those which are correctly labeled.","data-quality":0}
{"text":"To approach this issue, we present LabelVizier, a human-in-the-loop workflow that incorporates domain knowledge and user-specific requirements to reveal actionable insights into annotation flaws, then produce better-quality labels for large-scale multi-label datasets.","data-quality":0}
{"text":"Codes: https://github.com/wxjiao/ParroT","data-quality":0}
{"text":"Meanwhile, the ParroT models can also preserve the ability on general tasks with the Alpaca multi-task dataset involved in finetuning.","data-quality":0}
{"text":"al, 2022).","data-quality":0}
{"text":"ARMBench can be accessed at http://armbench.com","data-quality":0}
{"text":"However, most existing recommendation methods collect these ego graphs from all users to compose a global graph to obtain high-order collaborative information between users and items, and these centralized CF recommendation methods inevitably lead to a high risk of user privacy leakage.","data-quality":0}
{"text":"Additionally, if we are to observe a bad LISA catalog, we can rely on data from LIGO-Virgo to improve the quality of the constrains, bringing it closer to a median LISA catalog.   ","data-quality":0}
{"text":"Our datasets and the code for reproducing our experiments are available at https://github.com/yandex-research/heterophilous-graphs","data-quality":0}
{"text":"Experimentally, we show its effectiveness on several homophilous and heterophilous datasets.","data-quality":0}
{"text":"Experiments on Argoverse dataset show that FLTP significantly outperforms the model trained on local data.","data-quality":0}
{"text":"Online Social Network (OSN) has become a hotbed of fake news due to the low cost of information dissemination.","data-quality":0}
{"text":"In light of this, we propose a semi-decentralized federated ego graph learning framework for on-device recommendations, named SemiDFEGL, which introduces new device-to-device collaborations to improve scalability and reduce communication costs and innovatively utilizes predicted interacted item nodes to connect isolated ego graphs to augment local subgraphs such that the high-order user-item collaborative information could be used in a privacy-preserving manner.","data-quality":0}
